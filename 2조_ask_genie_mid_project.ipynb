{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2조  ask_genie_mid_project.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z8MyXAP12umb",
        "outputId": "2bc6655e-f5d7-4a1d-848f-fb3cd3729d48"
      },
      "source": [
        "pip install selenium"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting selenium\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/80/d6/4294f0b4bce4de0abf13e17190289f9d0613b0a44e5dd6a7f5ca98459853/selenium-3.141.0-py2.py3-none-any.whl (904kB)\n",
            "\u001b[K     |████████████████████████████████| 911kB 5.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: urllib3 in /usr/local/lib/python3.6/dist-packages (from selenium) (1.24.3)\n",
            "Installing collected packages: selenium\n",
            "Successfully installed selenium-3.141.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 746
        },
        "id": "_mcdmhLv20xl",
        "outputId": "63c3b1a1-e981-4fb0-a293-89d2c0e07a21"
      },
      "source": [
        "pip install konlpy"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting konlpy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/0e/f385566fec837c0b83f216b2da65db9997b35dd675e107752005b7d392b1/konlpy-0.5.2-py2.py3-none-any.whl (19.4MB)\n",
            "\u001b[K     |████████████████████████████████| 19.4MB 1.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (4.2.6)\n",
            "Collecting beautifulsoup4==4.6.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/d4/10f46e5cfac773e22707237bfcd51bbffeaf0a576b0a847ec7ab15bd7ace/beautifulsoup4-4.6.0-py3-none-any.whl (86kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 9.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.6/dist-packages (from konlpy) (1.19.5)\n",
            "Collecting tweepy>=3.7.0\n",
            "  Downloading https://files.pythonhosted.org/packages/67/c3/6bed87f3b1e5ed2f34bd58bf7978e308c86e255193916be76e5a5ce5dfca/tweepy-3.10.0-py2.py3-none-any.whl\n",
            "Collecting colorama\n",
            "  Downloading https://files.pythonhosted.org/packages/44/98/5b86278fbbf250d239ae0ecb724f8572af1c91f4a11edf4d36a206189440/colorama-0.4.4-py2.py3-none-any.whl\n",
            "Collecting JPype1>=0.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/af/93f92b38ec1ff3091cd38982ed19cea2800fefb609b5801c41fc43c0781e/JPype1-1.2.1-cp36-cp36m-manylinux2010_x86_64.whl (457kB)\n",
            "\u001b[K     |████████████████████████████████| 460kB 30.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.15.0)\n",
            "Requirement already satisfied: requests[socks]>=2.11.1 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (2.23.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n",
            "Requirement already satisfied: typing-extensions; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from JPype1>=0.7.0->konlpy) (3.7.4.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2.10)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6; extra == \"socks\" in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.7.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.0)\n",
            "Installing collected packages: beautifulsoup4, tweepy, colorama, JPype1, konlpy\n",
            "  Found existing installation: beautifulsoup4 4.6.3\n",
            "    Uninstalling beautifulsoup4-4.6.3:\n",
            "      Successfully uninstalled beautifulsoup4-4.6.3\n",
            "  Found existing installation: tweepy 3.6.0\n",
            "    Uninstalling tweepy-3.6.0:\n",
            "      Successfully uninstalled tweepy-3.6.0\n",
            "Successfully installed JPype1-1.2.1 beautifulsoup4-4.6.0 colorama-0.4.4 konlpy-0.5.2 tweepy-3.10.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "bs4"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQKfbUCJAB4H"
      },
      "source": [
        "\n",
        "\n",
        "from bs4 import BeautifulSoup \n",
        "import time\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "from selenium import webdriver\n",
        "import re\n",
        "from PIL import Image \n",
        "from wordcloud import WordCloud, ImageColorGenerator # Image 로부터 Color 를 생성(Generate)해내는 객체입니다.\n",
        "import numpy as np\n",
        "from sklearn import linear_model \n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity \n",
        "import matplotlib.pyplot as plt\n",
        "import requests\n",
        "from konlpy.tag import Okt\n",
        "%matplotlib inline\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zv77iLtYADm4"
      },
      "source": [
        "\n",
        "\n",
        "def ask_genie_any_product1(product_name1):\n",
        "    \n",
        "\n",
        "    \n",
        "    chrome_options = webdriver.ChromeOptions()\n",
        "    chrome_options.add_argument('--headless')\n",
        "    chrome_options.add_argument('--no-sandbox')\n",
        "    chrome_options.add_argument('--disable-dev-shm-usage')\n",
        "\n",
        "    driver = webdriver.Chrome(executable_path='(driver) chromedriver.exe',chrome_options=chrome_options)  # This is Mac version so if you use windows change the chromedriver path\n",
        "    #driver =webdriver.Chrome(executable_path='/Users/paulshin/anaconda3/bin/chromedriver',chrome_options=chrome_options)\n",
        "\n",
        "\n",
        "    url = 'https://shopping.naver.com/'\n",
        "    driver.get(url)\n",
        "    \n",
        "    driver.find_element_by_xpath('//*[@id=\"autocompleteWrapper\"]/input[1]').send_keys(product_name1) \n",
        "    driver.find_element_by_xpath('//*[@id=\"autocompleteWrapper\"]/a[2]').click()\n",
        "    url = driver.current_url\n",
        "    driver.get(url)\n",
        "    # 모든 상품 정보 \n",
        "    data={}\n",
        "    names = []\n",
        "    infos = []\n",
        "    like_nums = []\n",
        "    prices = []\n",
        "    \n",
        "    url_list = []\n",
        "\n",
        "    while 1995:\n",
        "        \n",
        "        \n",
        "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
        "        \n",
        "        web_page = BeautifulSoup(driver.page_source, 'html.parser')\n",
        "        #finding url \n",
        "        for find_url in web_page.find_all('a',{'class':'thumbnail_thumb__3Agq6'}):\n",
        "            try:\n",
        "                #리스트에 리뷰 추가\n",
        "                url_list.append(find_url.attrs['href'])\n",
        "            except: print('url error')\n",
        "        \n",
        "        for data in web_page.find_all('div',{'class':'basicList_info_area__17Xyo'}):\n",
        "            \n",
        "        # 하나씩 data에서 꺼내오기\n",
        "            try:\n",
        "                \n",
        "                #상품이름\n",
        "                name = data.find('a',{'class':'basicList_link__1MaTN'}).get_text()\n",
        "                #제품설명\n",
        "                info = data.find('div',{'class':'basicList_detail_box__3ta3h'}).get_text() \n",
        "                info = info.replace(' ','') #제품 설명속 공백제거 \n",
        "                info = info.replace('|',' ')\n",
        "                #찜 \n",
        "                like_num = data.find('em',{'class':'basicList_num__1yXM9'}).get_text()\n",
        "                like_num = like_num.replace(',','')\n",
        "                like_num = like_num.strip()\n",
        "                #가격\n",
        "                price = data.find('span',{'class':'price_num__2WUXn'}).get_text()\n",
        "                price = price.replace(',','')\n",
        "                price = price.replace('원','')\n",
        "                price= price.strip()\n",
        "                \n",
        "                \n",
        "                #리스트에 각요소 추가\n",
        "                names.append(name)\n",
        "                infos.append(info)\n",
        "                like_nums.append(like_num)\n",
        "                prices.append(price)\n",
        "\n",
        "\n",
        "                print('Process {}'.format(name))\n",
        "\n",
        "            except:\n",
        "\n",
        "                print('*** 다음 제품의 정보를 크롤링하는 중 에러가 발생했습니다 : {}'.format(name))  \n",
        "                \n",
        "                \n",
        "          \n",
        "            \n",
        "\n",
        "        \n",
        "        next_page = driver.find_element_by_class_name('pagination_next__1ITTf')\n",
        "        next_page.click()\n",
        "\n",
        "        time.sleep(5)\n",
        "\n",
        "        print('============= Next Page Click ========== ')\n",
        "        print('')\n",
        "\n",
        "        # 제품 개수 제한\n",
        "        if(len(names) > 100):\n",
        "            driver.close()\n",
        "            driver.quit()\n",
        "            break\n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "    data_frame_column_name= { \"name\": names, \"price\" : prices, \"Info\" : infos, \"like\": like_nums, 'url' : url_list}\n",
        "    product_name_df = pd.DataFrame(data_frame_column_name)\n",
        "\n",
        "    product_name_df =product_name_df[product_name_df.Info != '']\n",
        "    product_name_df[['price','like']] = product_name_df[['price','like']].astype(int) \n",
        "\n",
        "\n",
        "    product_name_df = product_name_df.sort_values(by='like', ascending=False)\n",
        "    product_name_df = product_name_df[:][:].reset_index()\n",
        "    product_name_df = product_name_df.drop(['index'], axis=1)\n",
        "    \n",
        "\n",
        "    product_name_df.to_csv('{}_df.csv'.format(product_name1), index=False)\n",
        "\n",
        "    info_dic = genie_show_product_keywords1(product_name_df)\n",
        "    word_dic = genie_show_product_review1(product_name_df)\n",
        "    \n",
        "    return genie_make_wordcloud1(info_dic,word_dic, color)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ycjxEk6TAIeS"
      },
      "source": [
        "def genie_show_product_keywords1(df):\n",
        "#-----------\n",
        "    # 문자열로 like기준으로 정렬하게 되면 1 10 2 30 이런 식으로 잘못 정렬하게됨 int로 고쳐주기\n",
        "    product_info = df['Info'].tolist()\n",
        "\n",
        "\n",
        "    for i in range(len(product_info)):\n",
        "        product_info[i] = re.sub(r'[^\\w\\s]',' ',product_info[i])\n",
        "\n",
        "    # 워드 클라우드 용\n",
        "    info = []\n",
        "    info_dic = {}\n",
        "    \n",
        "\n",
        "    for item in product_info:\n",
        "        for word in item.split(' '):\n",
        "            if(word != ''):\n",
        "                info.append(word)\n",
        "\n",
        "    for word in info:\n",
        "        if word not in info_dic:\n",
        "            info_dic[word] = 1\n",
        "        else:\n",
        "            info_dic[word] += 1\n",
        "            \n",
        "    new_info_dic = {key : value for key, value in info_dic.items() if value > 10}\n",
        "    \n",
        "    return new_info_dic "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cu73Wvc3ALfn"
      },
      "source": [
        "def genie_show_product_review1(df):\n",
        "    review = []\n",
        "    for web_url in df['url']: # 각 리뷰(url)에서 리뷰본문.get_text()\n",
        "\n",
        "        headers = {'User-Agent':'Mozilla/5.0 (Windows NT 6.3; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/63.0.3239.132 Safari/537.36'}\n",
        "        web = requests.get(web_url,headers=headers).content\n",
        "        product_web_page = BeautifulSoup(web, 'html.parser')\n",
        "\n",
        "        try:\n",
        "            article = product_web_page.find('p',{'class':'reviewItems_text__XIsTc'})\n",
        "            review.append(article.get_text())\n",
        "\n",
        "        except:\n",
        "            print('pass')\n",
        "\n",
        "\n",
        "    \n",
        "\n",
        "    articles = ' '.join(review)\n",
        "\n",
        "    review_to_csv = pd.DataFrame(review)\n",
        "    review_to_csv.to_csv('{}_review.txt'.format(product_name1))\n",
        "    \n",
        "    twitter = Okt()\n",
        "    raw_pos_tagged = twitter.pos(articles, norm=True, stem=True) # POS Tagging\n",
        "\n",
        "    \n",
        "    \n",
        "    common_list = ['하다', '있다', '되다', '이다', '돼다','매우', '않다','들다','정도','되어다','해보다','써다','쓰다','보다','자다','받다', '없다', '그렇다', '아니다', '이렇다', '그렇다', '어떻다', '광고', '크리스마스', '같다'] \n",
        "    stopwords_df = pd.read_json('stopwords-ko.json')\n",
        "    stopwords= stopwords_df[0].tolist()\n",
        "    word_cleaned = []\n",
        "    del_list = common_list + stopwords\n",
        "    # ('서울', 'Noun'),\n",
        "    for word in raw_pos_tagged: #  ('서울', 'Noun'),\n",
        "\n",
        "        if word[1] not in [\"Josa\", \"Eomi\", \"Punctuation\", \"Foreign\"]: # Foreign == ”, “ 와 같이 제외되어야할 항목들\n",
        "            if (len(word[0]) != 1) & (word[0] not in del_list): # 한 글자로 이뤄진 단어들을 제외 & 원치 않는 단어들을 제외 \n",
        "                word_cleaned.append(word[0])\n",
        "                \n",
        "    word_dic = {}\n",
        "\n",
        "    for word in word_cleaned:\n",
        "        if word not in word_dic:\n",
        "            word_dic[word] = 1 # changed from \"0\" to \"1\"\n",
        "        else:\n",
        "            word_dic[word] += 1\n",
        "            \n",
        "    result = Counter(word_cleaned)\n",
        "    word_dic = dict(result)        \n",
        "            \n",
        "    return word_dic\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3sy5JFuhAODR"
      },
      "source": [
        "def genie_make_wordcloud1(info_dic, word_dic, color) :\n",
        "    key_word_logo = np.array(Image.open(\"lamp.jpeg\"))\n",
        "\n",
        "    function_cloud= WordCloud(font_path=\"C:/Users/LG/Desktop/ELAND_M.ttf\", \n",
        "                              #font_path=\"/Users/paulshin/Library/Fonts/ELAND 나이스OTF M.otf\"\n",
        "                     width=2000, height=1000,\n",
        "                     max_words=50, # 단어 70개만 표시\n",
        "                     mask=key_word_logo,\n",
        "                     background_color='black',\n",
        "                     colormap = '{}'.format(color))\n",
        "    \n",
        "    review_word_logo = np.array(Image.open(\"naver.png\"))\n",
        "\n",
        "    review_cloud= WordCloud(font_path=\"C:/Users/LG/Desktop/ELAND_M.ttf\",\n",
        "                 width=2000, height=1000,\n",
        "                 max_words=100, # 단어 70개만 표시\n",
        "                 mask=review_word_logo,\n",
        "                 background_color='black',\n",
        "                 colormap = '{}'.format(color))\n",
        "                     \n",
        "    \n",
        "    \n",
        "\n",
        "     function_cloud.generate_from_frequencies(info_dic) \n",
        "    review_cloud.generate_from_frequencies(word_dic)\n",
        "    \n",
        "    plt.figure(figsize=(13,13))\n",
        "    plt.imshow(function_cloud)\n",
        "    plt.axis(\"off\")\n",
        "    plt.tight_layout(pad=0)\n",
        "    plt.savefig('{}_keyword_wordcloud.png'.format(product_name1))\n",
        "    plt.show()\n",
        "    \n",
        "    \n",
        "    plt.figure(figsize=(13,13))\n",
        "    plt.imshow(review_cloud)\n",
        "    plt.axis(\"off\")\n",
        "    plt.tight_layout(pad=0)\n",
        "    plt.savefig('{}_review_wordcloud.png'.format(product_name1))\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fSmL9KEzAq4w",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 536
        },
        "outputId": "2e0b3aee-c706-4006-8d40-13db51822a3f"
      },
      "source": [
        "product_name1 = input('지니에게 검색을 부탁하세요 : ')\n",
        "color = input('지니에게 원하는 색을 알려주세요 (Blues, Reds, Greens, Oranges, Purples) : ')\n",
        "ask_genie_any_product1(product_name1) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "지니에게 검색을 부탁하세요 : vans\n",
            "지니에게 원하는 색을 알려주세요 (Blues, Reds, Greens, Oranges, Purples) : Greens\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: DeprecationWarning: use options instead of chrome_options\n",
            "  if sys.path[0] == '':\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "WebDriverException",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/selenium/webdriver/common/service.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     75\u001b[0m                                             \u001b[0mstderr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_file\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m                                             stdin=PIPE)\n\u001b[0m\u001b[1;32m     77\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/subprocess.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, encoding, errors)\u001b[0m\n\u001b[1;32m    728\u001b[0m                                 \u001b[0merrread\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrwrite\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m                                 restore_signals, start_new_session)\n\u001b[0m\u001b[1;32m    730\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/subprocess.py\u001b[0m in \u001b[0;36m_execute_child\u001b[0;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, start_new_session)\u001b[0m\n\u001b[1;32m   1363\u001b[0m                             \u001b[0merr_msg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m': '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1364\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mchild_exception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrno_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1365\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mchild_exception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '(driver) chromedriver.exe': '(driver) chromedriver.exe'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mWebDriverException\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-e8b68f60e7db>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mproduct_name1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'지니에게 검색을 부탁하세요 : '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mcolor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'지니에게 원하는 색을 알려주세요 (Blues, Reds, Greens, Oranges, Purples) : '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mask_genie_any_product1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproduct_name1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-7-e7069a025987>\u001b[0m in \u001b[0;36mask_genie_any_product1\u001b[0;34m(product_name1)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mchrome_options\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_argument\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'--disable-dev-shm-usage'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mdriver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwebdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mChrome\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexecutable_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'(driver) chromedriver.exe'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mchrome_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchrome_options\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# This is Mac version so if you use windows change the chromedriver path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0;31m#driver =webdriver.Chrome(executable_path='/Users/paulshin/anaconda3/bin/chromedriver',chrome_options=chrome_options)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/selenium/webdriver/chrome/webdriver.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, executable_path, port, options, service_args, desired_capabilities, service_log_path, chrome_options, keep_alive)\u001b[0m\n\u001b[1;32m     71\u001b[0m             \u001b[0mservice_args\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mservice_args\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             log_path=service_log_path)\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mservice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/selenium/webdriver/common/service.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     81\u001b[0m                 raise WebDriverException(\n\u001b[1;32m     82\u001b[0m                     \"'%s' executable needs to be in PATH. %s\" % (\n\u001b[0;32m---> 83\u001b[0;31m                         os.path.basename(self.path), self.start_error_message)\n\u001b[0m\u001b[1;32m     84\u001b[0m                 )\n\u001b[1;32m     85\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrno\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0merrno\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEACCES\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mWebDriverException\u001b[0m: Message: '(driver) chromedriver.exe' executable needs to be in PATH. Please see https://sites.google.com/a/chromium.org/chromedriver/home\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "alV3vFCJBn41"
      },
      "source": [
        "#-----------------------above is 1 below is two"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ewcl1pR4_Ym1"
      },
      "source": [
        "#------------------------\n",
        "#testing\n",
        "\n",
        "def ask_genie_any_product2(product_name2):\n",
        "    \n",
        "\n",
        "    \n",
        "    chrome_options = webdriver.ChromeOptions()\n",
        "    chrome_options.add_argument('--headless')\n",
        "    chrome_options.add_argument('--no-sandbox')\n",
        "    chrome_options.add_argument('--disable-dev-shm-usage')\n",
        "\n",
        "    driver = webdriver.Chrome(executable_path='(driver) chromedriver.exe',chrome_options=chrome_options)\n",
        "\n",
        "\n",
        "    url = 'https://shopping.naver.com/'\n",
        "    driver.get(url)\n",
        "    \n",
        "    driver.find_element_by_xpath('//*[@id=\"autocompleteWrapper\"]/input[1]').send_keys(product_name2) # (영화이름 + 년도)로 검색\n",
        "    driver.find_element_by_xpath('//*[@id=\"autocompleteWrapper\"]/a[2]').click()\n",
        "    url = driver.current_url\n",
        "    driver.get(url)\n",
        "    # 모든 상품 정보 \n",
        "    data={}\n",
        "    names = []\n",
        "    infos = []\n",
        "    like_nums = []\n",
        "    prices = []\n",
        "    \n",
        "    url_list = []\n",
        "\n",
        "    while 1995:\n",
        "        \n",
        "        \n",
        "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
        "        \n",
        "        web_page = BeautifulSoup(driver.page_source, 'html.parser')\n",
        "        #finding url \n",
        "        for find_url in web_page.find_all('a',{'class':'thumbnail_thumb__3Agq6'}):\n",
        "            try:\n",
        "                #리스트에 리뷰 추가\n",
        "                url_list.append(find_url.attrs['href'])\n",
        "            except: print('url error')\n",
        "        \n",
        "        for data in web_page.find_all('div',{'class':'basicList_info_area__17Xyo'}):\n",
        "            \n",
        "        # 하나씩 data에서 꺼내오기\n",
        "            try:\n",
        "                \n",
        "                #상품이름\n",
        "                name = data.find('a',{'class':'basicList_link__1MaTN'}).get_text()\n",
        "                #제품설명\n",
        "                info = data.find('div',{'class':'basicList_detail_box__3ta3h'}).get_text() \n",
        "                info = info.replace(' ','') #제품 설명속 공백제거 \n",
        "                info = info.replace('|',' ')\n",
        "                #찜 \n",
        "                like_num = data.find('em',{'class':'basicList_num__1yXM9'}).get_text()\n",
        "                like_num = like_num.replace(',','')\n",
        "                like_num = like_num.strip()\n",
        "                #가격\n",
        "                price = data.find('span',{'class':'price_num__2WUXn'}).get_text()\n",
        "                price = price.replace(',','')\n",
        "                price = price.replace('원','')\n",
        "                price= price.strip()\n",
        "                \n",
        "                \n",
        "                #리스트에 각요소 추가\n",
        "                names.append(name)\n",
        "                infos.append(info)\n",
        "                like_nums.append(like_num)\n",
        "                prices.append(price)\n",
        "\n",
        "\n",
        "                print('Process {}'.format(name))\n",
        "\n",
        "            except:\n",
        "\n",
        "                print('*** 다음 제품의 정보를 크롤링하는 중 에러가 발생했습니다 : {}'.format(name))  \n",
        "                \n",
        "                \n",
        "          \n",
        "            \n",
        "\n",
        "        #   driver.find_element_by_class_name('pagination_next__1ITTf').click()\n",
        "        next_page = driver.find_element_by_class_name('pagination_next__1ITTf')\n",
        "        next_page.click()\n",
        "\n",
        "        time.sleep(5)\n",
        "\n",
        "        print('============= Next Page Click ========== ')\n",
        "        print('')\n",
        "\n",
        "        # 제품 개수 제한\n",
        "        if(len(names) > 100):\n",
        "            driver.close()\n",
        "            driver.quit()\n",
        "            break\n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "    data_frame_column_name= { \"name\": names, \"price\" : prices, \"Info\" : infos, \"like\": like_nums, 'url' : url_list}\n",
        "    product_name_df = pd.DataFrame(data_frame_column_name)\n",
        "\n",
        "    product_name_df =product_name_df[product_name_df.Info != '']\n",
        "    product_name_df[['price','like']] = product_name_df[['price','like']].astype(int) \n",
        "\n",
        "\n",
        "    product_name_df = product_name_df.sort_values(by='like', ascending=False)\n",
        "    product_name_df = product_name_df[:][:].reset_index()\n",
        "    product_name_df = product_name_df.drop(['index'], axis=1)\n",
        "    \n",
        "\n",
        "    product_name_df.to_csv('{}_df.csv'.format(product_name2), index=False)\n",
        "\n",
        "    info_dic = genie_show_product_keywords2(product_name_df)\n",
        "    word_dic = genie_show_product_review2(product_name_df)\n",
        "    genie_make_wordcloud2(info_dic, word_dic, color1)\n",
        "    \n",
        "    return genie_make_wordcloud2(info_dic, word_dic, color1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mf9P2A7J_ZR2"
      },
      "source": [
        "def genie_show_product_keywords2(df):\n",
        "#-----------\n",
        "    # 문자열로 like기준으로 정렬하게 되면 1 10 2 30 이런 식으로 잘못 정렬하게됨 int로 고쳐주기\n",
        "    product_info = df['Info'].tolist()\n",
        "\n",
        "\n",
        "    for i in range(len(product_info)):\n",
        "        product_info[i] = re.sub(r'[^\\w\\s]',' ',product_info[i])\n",
        "\n",
        "    # 워드 클라우드 용\n",
        "    info = []\n",
        "    info_dic = {}\n",
        "    \n",
        "\n",
        "    for item in product_info:\n",
        "        for word in item.split(' '):\n",
        "            if(word != ''):\n",
        "                info.append(word)\n",
        "\n",
        "    for word in info:\n",
        "        if word not in info_dic:\n",
        "            info_dic[word] = 1\n",
        "        else:\n",
        "            info_dic[word] += 1\n",
        "            \n",
        "    new_info_dic = {key : value for key, value in info_dic.items() if value > 10}\n",
        "    \n",
        "    return new_info_dic "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GqVpKAni_ZX2"
      },
      "source": [
        "def genie_show_product_review2(df):\n",
        "    review = []\n",
        "    for web_url in df['url']: # 각 리뷰(url)에서 리뷰본문.get_text()\n",
        "\n",
        "        headers = {'User-Agent':'Mozilla/5.0 (Windows NT 6.3; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/63.0.3239.132 Safari/537.36'}\n",
        "        web = requests.get(web_url,headers=headers).content\n",
        "        product_web_page = BeautifulSoup(web, 'html.parser')\n",
        "\n",
        "        try:\n",
        "            article = product_web_page.find('p',{'class':'reviewItems_text__XIsTc'})\n",
        "            review.append(article.get_text())\n",
        "\n",
        "        except:\n",
        "            print('pass')\n",
        "\n",
        "    \n",
        "\n",
        "    articles = ' '.join(review)\n",
        "    \n",
        "    review_to_csv = pd.DataFrame(review)\n",
        "    review_to_csv.to_csv('{}_review.txt'.format(product_name2))\n",
        "\n",
        "\n",
        "\n",
        "    twitter = Okt()\n",
        "    raw_pos_tagged = twitter.pos(articles, norm=True, stem=True) # POS Tagging\n",
        "\n",
        "    \n",
        "    \n",
        "    common_list = ['하다', '있다', '되다', '이다', '돼다','매우', '않다','들다','정도','되어다','해보다','써다','쓰다','보다','자다','받다', '없다', '그렇다', '아니다', '이렇다', '그렇다', '어떻다', '광고', '크리스마스', '같다'] \n",
        "    stopwords_df = pd.read_json('stopwords-ko.json')\n",
        "    stopwords= stopwords_df[0].tolist()\n",
        "    word_cleaned = []\n",
        "    del_list = common_list + stopwords\n",
        "    # ('서울', 'Noun'),\n",
        "    for word in raw_pos_tagged: #  ('서울', 'Noun'),\n",
        "\n",
        "        if word[1] not in [\"Josa\", \"Eomi\", \"Punctuation\", \"Foreign\"]: # Foreign == ”, “ 와 같이 제외되어야할 항목들\n",
        "            if (len(word[0]) != 1) & (word[0] not in del_list): # 한 글자로 이뤄진 단어들을 제외 & 원치 않는 단어들을 제외 \n",
        "                word_cleaned.append(word[0])\n",
        "                \n",
        "    word_dic = {}\n",
        "\n",
        "    for word in word_cleaned:\n",
        "        if word not in word_dic:\n",
        "            word_dic[word] = 1 # changed from \"0\" to \"1\"\n",
        "        else:\n",
        "            word_dic[word] += 1\n",
        "            \n",
        "    result = Counter(word_cleaned)\n",
        "    word_dic = dict(result)        \n",
        "            \n",
        "    return word_dic\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cFX3jyyi_ZcQ"
      },
      "source": [
        "def genie_make_wordcloud2(info_dic, word_dic, color1) :\n",
        "    key_word_logo = np.array(Image.open(\"lamp.jpeg\"))\n",
        "\n",
        "    function_cloud= WordCloud(font_path=\"C:/Windows/Fonts/malgun.ttf\",\n",
        "                     width=2000, height=1000,\n",
        "                     max_words=50, # 단어 70개만 표시\n",
        "                     mask=key_word_logo,\n",
        "                     background_color='white',\n",
        "                     colormap = '{}'.format(color1))\n",
        "    \n",
        "    review_word_logo = np.array(Image.open(\"naver.png\"))\n",
        "\n",
        "    review_cloud= WordCloud(font_path=\"C:/Windows/Fonts/malgun.ttf\",\n",
        "                 width=2000, height=1000,\n",
        "                 max_words=100, # 단어 70개만 표시\n",
        "                 mask=review_word_logo,\n",
        "                 background_color='black',\n",
        "                 colormap = '{}'.format(color1))\n",
        "                     \n",
        "    \n",
        "    \n",
        "\n",
        "     function_cloud.generate_from_frequencies(info_dic) \n",
        "    review_cloud.generate_from_frequencies(word_dic)\n",
        "    \n",
        "    plt.figure(figsize=(13,13))\n",
        "    plt.imshow(function_cloud)\n",
        "    plt.axis(\"off\")\n",
        "    plt.tight_layout(pad=0)\n",
        "    plt.savefig('{}_keyword_wordcloud.png'.format(product_name1))\n",
        "    plt.show()\n",
        "    \n",
        "    \n",
        "    plt.figure(figsize=(13,13))\n",
        "    plt.imshow(review_cloud)\n",
        "    plt.axis(\"off\")\n",
        "    plt.tight_layout(pad=0)\n",
        "    plt.savefig('{}_review_wordcloud.png'.format(product_name1))\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lrtJR6hM_Zh-"
      },
      "source": [
        "product_name2 = input('지니에게 한번더 검색을 부탁하세요 : ')\n",
        "color1 = input('지니에게 좋아하는 색갈을 골라 주세요 (Blues, Reds, Greens, Oranges, Purples) : ')\n",
        "ask_genie_any_product2(product_name2) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lybkCJ_J_ZmV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QeoiKpM6_Zqe"
      },
      "source": [
        "#Finding similarity between two products"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "whQ7YYjN_ZuL"
      },
      "source": [
        "#Finding the cosine similarity of the two product reviews"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QGJUwz3Q2xll"
      },
      "source": [
        "def measure_similarity(csv_file_name1,csv_file_name2) :\r\n",
        "    \r\n",
        "\r\n",
        "    \r\n",
        "    \r\n",
        "    df_1= pd.read_csv(csv_file_name1,index_col= [0])\r\n",
        "    df_2 = pd.read_csv(csv_file_name2,index_col= [0])\r\n",
        "    \r\n",
        "    df_1.dropna(inplace = True)\r\n",
        "    df_2.dropna(inplace = True)\r\n",
        "    \r\n",
        "    doc1 = ''\r\n",
        "    for line in df_1['0'] : \r\n",
        "        doc1 += line\r\n",
        "    \r\n",
        "    doc2 = ''\r\n",
        "    for line in df_2['0'] : \r\n",
        "        doc2 += line\r\n",
        "    \r\n",
        "    corpus = [doc1, doc2]  # doc1, doc2를 합쳐 corpus list를 생성\r\n",
        "    \r\n",
        "    vectorizer = TfidfVectorizer()\r\n",
        "    X = vectorizer.fit_transform(corpus).todense()\r\n",
        "    \r\n",
        "    return print(\"Similarity between two products : \", cosine_similarity(X[0], X[1]) )\r\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F7mecaAgMz20"
      },
      "source": [
        "measure_similarity('{}_review.txt'.format(product_name1), '{}_review.txt'.format(product_name2))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}